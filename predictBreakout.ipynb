{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing useful librairies and setting plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('./functions')\n",
    "from indicators import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (30, 15)\n",
    "plt.rcParams['figure.facecolor'] = \"white\"\n",
    "plt.rcParams['axes.facecolor'] = \"white\"\n",
    "plt.rcParams['axes.edgecolor'] = \"black\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading csv files w/ cryptocurrency data and merge them together\n",
    "\n",
    "Loading indicators, cleaning dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d or 4h\n",
    "path = r'data/1d'\n",
    "all_files = glob.glob(path + '/*.csv')\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    data = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(data)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "data = frame.set_index(frame['date'])\n",
    "data.index = pd.to_datetime(data.index, unit='ms')\n",
    "del data['date']\n",
    "\n",
    "# POSITIVE BREAKOUT\n",
    "get_indicators(data)\n",
    "\n",
    "del data['open']\n",
    "del data['high']\n",
    "del data['low']\n",
    "\n",
    "data['pct_change'] = data.close.pct_change().shift(-1)\n",
    "data['previous_pct_change'] = data.close.pct_change()\n",
    "data['2previous_pct_change'] = data.close.pct_change().shift(1)\n",
    "del data['close']\n",
    "\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining 3 binary variables (% change between two days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    30134\n",
       "1.0       26\n",
       "Name: pct_change, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    df['pct_change'][index] = np.where(\n",
    "        df['pct_change'][index] > 0.6, 1, 0)  # asset up, define by how much\n",
    "    df['previous_pct_change'][index] = np.where(\n",
    "        df['previous_pct_change'][index] > 0, 1, 0)\n",
    "    df['2previous_pct_change'][index] = np.where(\n",
    "        df['2previous_pct_change'][index] > 0, 1, 0)\n",
    "\n",
    "df_ = df.dropna()\n",
    "\n",
    "# Counting values for each class\n",
    "df_['pct_change'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining predictor and target variables, randomizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('pct_change', axis=1)\n",
    "y = dataset['pct_change']\n",
    "\n",
    "X, y = shuffle(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over sampling minority class to deal w/ imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    21096\n",
       "0.0    21096\n",
       "Name: pct_change, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two different dataframe of majority and minority class\n",
    "df_majority = X[(X['pct_change'] == 0)]\n",
    "df_minority = X[(X['pct_change'] == 1)]\n",
    "# upsample minority class\n",
    "minority_upsampled = resample(df_minority,\n",
    "                              replace=True,    # sample with replacement\n",
    "                              # to match majority class\n",
    "                              n_samples=len(df_majority),\n",
    "                              random_state=0)  # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "oversampled = pd.concat([minority_upsampled, df_majority])\n",
    "oversampled['pct_change'].value_counts()\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "# Fit the model to generate the data.\n",
    "# oversampled_X, oversampled_Y = sm.fit_resample(\n",
    "#    X.drop('pct_change', axis=1), X['pct_change'])\n",
    "# oversampledSmote = pd.concat(\n",
    "#    [pd.DataFrame(oversampled_X), pd.DataFrame(oversampled_Y)], axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = oversampled.drop('pct_change', axis=1)\n",
    "y = oversampled['pct_change']\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(feature_scaler.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(feature_scaler.transform(X_test))\n",
    "X_train.columns = X.columns\n",
    "X_test.columns = X.columns\n",
    "X = pd.DataFrame(feature_scaler.fit_transform(X))\n",
    "X.columns = X_train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining categorical and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = []\n",
    "num_data = []\n",
    "\n",
    "for i, c in enumerate(X_train.dtypes):\n",
    "    if c == object:\n",
    "        cat_data.append(X_train.iloc[:, i])\n",
    "    else:\n",
    "        num_data.append(X_train.iloc[:, i])\n",
    "\n",
    "cat_data = pd.DataFrame(cat_data).transpose()\n",
    "num_data = pd.DataFrame(num_data).transpose()\n",
    "\n",
    "# Identify Numeric features\n",
    "num_features = num_data.columns.values\n",
    "# Identify Categorical features\n",
    "cat_features = cat_data.columns.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>stochOsc</td>\n",
       "      <td>willR</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>kama</td>\n",
       "      <td>VWAP</td>\n",
       "      <td>0.998006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>VWAP</td>\n",
       "      <td>PSAR</td>\n",
       "      <td>0.996188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>kama</td>\n",
       "      <td>PSAR</td>\n",
       "      <td>0.994637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>bbWidth</td>\n",
       "      <td>DONC</td>\n",
       "      <td>0.992580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kama</td>\n",
       "      <td>ATR</td>\n",
       "      <td>0.964302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>VWAP</td>\n",
       "      <td>ATR</td>\n",
       "      <td>0.963160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>stochOsc</td>\n",
       "      <td>dcPer</td>\n",
       "      <td>0.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>willR</td>\n",
       "      <td>dcPer</td>\n",
       "      <td>0.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>ATR</td>\n",
       "      <td>PSAR</td>\n",
       "      <td>0.958852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>bbPer</td>\n",
       "      <td>CCI</td>\n",
       "      <td>0.957916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>VPT</td>\n",
       "      <td>DONC</td>\n",
       "      <td>0.954712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>VPT</td>\n",
       "      <td>bbWidth</td>\n",
       "      <td>0.930134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>RSI</td>\n",
       "      <td>TSI</td>\n",
       "      <td>0.922945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>ADI</td>\n",
       "      <td>OBV</td>\n",
       "      <td>0.919773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>RSI</td>\n",
       "      <td>bbPer</td>\n",
       "      <td>0.910117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>MFI</td>\n",
       "      <td>VI</td>\n",
       "      <td>0.908699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1 feature2  corr_coef\n",
       "261  stochOsc    willR   1.000000\n",
       "95       kama     VWAP   0.998006\n",
       "604      VWAP     PSAR   0.996188\n",
       "111      kama     PSAR   0.994637\n",
       "649   bbWidth     DONC   0.992580\n",
       "96       kama      ATR   0.964302\n",
       "589      VWAP      ATR   0.963160\n",
       "275  stochOsc    dcPer   0.962900\n",
       "368     willR    dcPer   0.962900\n",
       "624       ATR     PSAR   0.958852\n",
       "638     bbPer      CCI   0.957916\n",
       "571       VPT     DONC   0.954712\n",
       "570       VPT  bbWidth   0.930134\n",
       "192       RSI      TSI   0.922945\n",
       "390       ADI      OBV   0.919773\n",
       "205       RSI    bbPer   0.910117\n",
       "517       MFI       VI   0.908699"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_correlated_features(df, threshold):\n",
    "    # Get correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "    # Take half of the matrix to prevent doubling results\n",
    "    corr_matrix = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # Restructure correlation matrix to dataframe\n",
    "    df = corr_matrix.stack().reset_index()\n",
    "    df.columns = ['feature1', 'feature2', 'corr_coef']\n",
    "    # Apply filter and sort coefficients\n",
    "    df = df[df.corr_coef >= threshold].sort_values(\n",
    "        'corr_coef', ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "find_correlated_features(X_train, .9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VI', 'willR', 'dcPer', 'bbPer', 'OBV', 'TSI', 'bbWidth', 'DONC', 'CCI', 'ATR', 'VWAP', 'PSAR'}\n"
     ]
    }
   ],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "for i in range(len(correlation_matrix .columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.9:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "print(correlated_features)\n",
    "X_train.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=correlated_features, axis=1, inplace=True)\n",
    "X.drop(labels=correlated_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortlist of ML algorithms to be tested:\n",
    "\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics\n",
    "\n",
    "- Precision/Specificity: how many selected instances are relevant.\n",
    "- Recall/Sensitivity: how many relevant instances are selected.\n",
    "- F1 score: harmonic mean of precision and recall.\n",
    "- AUC: relation between true-positive rate and false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 92.79 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92      6333\n",
      "         1.0       0.87      1.00      0.93      6325\n",
      "\n",
      "    accuracy                           0.93     12658\n",
      "   macro avg       0.94      0.93      0.93     12658\n",
      "weighted avg       0.94      0.93      0.93     12658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "# print(confusion_matrix(y_test, predictions))\n",
    "print('Accuracy : {} %'.format(\n",
    "    round(accuracy_score(y_test, predictions).mean()*100, 2)))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 99.99 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      6333\n",
      "         1.0       1.00      1.00      1.00      6325\n",
      "\n",
      "    accuracy                           1.00     12658\n",
      "   macro avg       1.00      1.00      1.00     12658\n",
      "weighted avg       1.00      1.00      1.00     12658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "# print(confusion_matrix(y_test, predictions))\n",
    "print('Accuracy : {} %'.format(\n",
    "    round(accuracy_score(y_test, predictions).mean()*100, 2)))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, X_train, y_train, _cv=10):\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=_cv,\n",
    "                             scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "\n",
    "    return {\"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "            \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "            \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "            \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "            \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "            \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "            \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "            \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 92.86 %\n",
      "Accuracy std : 0.0046600368951547075\n",
      "\n",
      "\n",
      "test_neg_mean_squared_error mean : -0.07137509311417123\n",
      "train_r2 mean : 0.7164097042959995\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Mean Training Accuracy': 92.91024313179452,\n",
       " 'Mean Training Precision': 0.8758464481017905,\n",
       " 'Mean Training Recall': 1.0,\n",
       " 'Mean Training F1 Score': 0.9338138217457074,\n",
       " 'Mean Validation Accuracy': 92.86249068858288,\n",
       " 'Mean Validation Precision': 0.875170112059147,\n",
       " 'Mean Validation Recall': 1.0,\n",
       " 'Mean Validation F1 Score': 0.9334145856499816}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0)\n",
    "# print(cross_val_score(model, X_train, y_train, cv=10))\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=10)\n",
    "print('Accuracy mean : {} %'.format(\n",
    "    round(cv_results['test_score'].mean()*100, 2)))\n",
    "print('Accuracy std : {}'.format(\n",
    "    cv_results['test_score'].std()))\n",
    "print('\\n')\n",
    "scores = cross_validate(model, X_train, y_train, cv=10,\n",
    "                        scoring=('r2', 'neg_mean_squared_error'),\n",
    "                        return_train_score=True)\n",
    "print('test_neg_mean_squared_error mean : {}'.format(\n",
    "    scores['test_neg_mean_squared_error'].mean()))\n",
    "print('train_r2 mean : {}'.format(\n",
    "    scores['train_r2'].mean()))\n",
    "print('\\n')\n",
    "cross_validation(model, X_train, y_train, _cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy mean : 100.0 %\n",
      "Accuracy std : 0.0\n",
      "\n",
      "\n",
      "test_neg_mean_squared_error mean : 0.0\n",
      "train_r2 mean : 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Mean Training Accuracy': 100.0,\n",
       " 'Mean Training Precision': 1.0,\n",
       " 'Mean Training Recall': 1.0,\n",
       " 'Mean Training F1 Score': 1.0,\n",
       " 'Mean Validation Accuracy': 100.0,\n",
       " 'Mean Validation Precision': 1.0,\n",
       " 'Mean Validation Recall': 1.0,\n",
       " 'Mean Validation F1 Score': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0)\n",
    "# print(cross_val_score(model, X_train, y_train, cv=10))\n",
    "cv_results = cross_validate(model, X_train, y_train, cv=10)\n",
    "print('Accuracy mean : {} %'.format(\n",
    "    round(cv_results['test_score'].mean()*100, 2)))\n",
    "print('Accuracy std : {}'.format(\n",
    "    cv_results['test_score'].std()))\n",
    "print('\\n')\n",
    "scores = cross_validate(model, X_train, y_train, cv=10,\n",
    "                        scoring=('r2', 'neg_mean_squared_error'),\n",
    "                        return_train_score=True)\n",
    "print('test_neg_mean_squared_error mean : {}'.format(\n",
    "    scores['test_neg_mean_squared_error'].mean()))\n",
    "print('train_r2 mean : {}'.format(\n",
    "    scores['train_r2'].mean()))\n",
    "print('\\n')\n",
    "cross_validation(model, X_train, y_train, _cv=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a62688940e3e309b135b035874dc806b7f687c649931f7414c3a46ac665adf16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
